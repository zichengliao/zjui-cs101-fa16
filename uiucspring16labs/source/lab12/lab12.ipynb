{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `lab12`—Optimizing over Time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "❖ Objectives\n",
    "\n",
    "-   Understand the effect of code structure and algorithm choice on code run time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Relative Efficiency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since there are many ways to solve most problems in computational science, let's investigate one such case.  If you have a list of objects and need to find duplicates, how would you go about it?  Naïvely, you can simply search through the list, comparing each object to each other and accruing the duplicates to a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "numbers = [12, 15, 12, 2, 6, 7, 1, 2, 2]\n",
    "duplicates = []\n",
    "\n",
    "for i in range(0, len(numbers)):  # note that we are making the range explicit here\n",
    "    for j in range(0, len(numbers)):\n",
    "        if i == j:  # don't compare numbers[0] to numbers[0], etc.\n",
    "            continue\n",
    "        if numbers[i] == numbers[j]:\n",
    "            duplicates.append(numbers[j])\n",
    "\n",
    "print(duplicates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That turns out to be overkill for this problem:  each case of a duplicate numbers sees the other as well, so you see pairs of duplicates rather than just the duplicate numbers.  (That is, we want the list `duplicates` to contain only `[12, 2]` rather than `[12, 12, 2, 2, 2, 2, 2, 2]`.\n",
    "\n",
    "-   Compose a function `find_duplicates` which accepts a list `values`.  The function `find_duplicates` should return only the numbers which have duplicates (and only one of each).  Use the code above (without modifying the algorithm); you will also need a comparison of the type\n",
    "        \n",
    "        values[j] not in duplicates\n",
    "    \n",
    "    to catch multiple duplicates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Write your function here.  This includes any necessary import statements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# it should pass this test---do NOT edit this cell\n",
    "from nose.tools import assert_equal\n",
    "\n",
    "test_values = ['a', 'a', 'b', 'd', 'a', 'b', 'c', 'd', 'a']\n",
    "test_result = find_duplicates(test_values)\n",
    "assert_equal(type(test_result), list, msg=\"\\nYour function doesn't return a list.\")\n",
    "assert_equal(len(test_result), 3, msg=\"\\nYour function does not return the correct number of duplicate items.\")\n",
    "assert_equal(test_result, ['a', 'b', 'd'], msg=\"\\nYour function returns the wrong items as duplicates.\")\n",
    "\n",
    "print('All tests passed successfully.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A simple optimization can be made to improve this code, particularly for large lists.  We are comparing each value to all others, *even the ones that have already been checked*.  This means that in many cases, we already know that something is a duplicate.  In graphical form, we are doing this:\n",
    "\n",
    "<img src=\"./img/duplicate-all.png\" width=\"40%;\" />\n",
    "\n",
    "when we could be doing this:\n",
    "\n",
    "<img src=\"./img/duplicate-half.png\" width=\"40%;\" />\n",
    "\n",
    "because we *already checked* the previous (left-hand) values for duplicateness.\n",
    "\n",
    "The relevant change:  switch the range of the `j` loop from `(0, len(values))` to `(i+1, len(values))`.\n",
    "\n",
    "-   Compose a new function `better_find_duplicates` which makes this change."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "better_find_duplicates",
     "locked": false,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# Write your function here.  This includes any necessary import statements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "better_find_duplicates-test",
     "locked": true,
     "points": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# it should pass this test---do NOT edit this cell\n",
    "from nose.tools import assert_equal\n",
    "\n",
    "test_values = ['a', 'a', 'b', 'd', 'a', 'b', 'c', 'd', 'a']\n",
    "test_result = better_find_duplicates(test_values)\n",
    "assert_equal(type(test_result), list, msg=\"\\nYour function doesn't return a list.\")\n",
    "assert_equal(len(test_result), 3, msg=\"\\nYour function does not return the correct number of duplicate items.\")\n",
    "assert_equal(test_result, ['a', 'b', 'd'], msg=\"\\nYour function returns the wrong items as duplicates.\")\n",
    "\n",
    "print('All tests passed successfully.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we intend to do now is compare the relative speeds of these two functions for large sets of data.  A reasonable hypothesis is that the second function, `better_find_duplicates`, is twice as fast as `find_duplicates`, since it requires only half as many tests.  We'll see if we can confirm or discard this guess.\n",
    "\n",
    "There are a few good ways to time code in Python.  You saw `time.time` in the lecture—it returns the current computer time, which we can use before and after a process.  A more automatic way is the `%timeit` command, which is explicitly designed to test functions repeatedly and report their run time.  (The percent sign in front means that this is a Jupyter notebook command, rather than a specifically Python command.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "basic-caesar",
     "locked": false,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "trial_values1 = list(range(16))*2\n",
    "print(trial_values1)\n",
    "%timeit find_duplicates(trial_values1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`%timeit` runs your code many times and reports the shortest run time from that set.  (This may be affected by other programs running on your computer as well.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(trial_values1)\n",
    "%timeit better_find_duplicates(trial_values1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On my machine, I had the following results:\n",
    "\n",
    "| function | best time |\n",
    "|----------|-----------|\n",
    "| `find_duplicates` | 176 µs |\n",
    "| `better_find_duplicates` | 99 µs |\n",
    "\n",
    "$99/176 = 0.5625$—that's pretty close to twice as fast (half the time), and we could reasonably expect that to improve as the data set becomes larger.  (Ideal behavior is often achieved with larger data sets since there is additional overhead from the function call and return which becomes a smaller proportion of bigger problems.)\n",
    "\n",
    "Let's use a bigger data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trial_values2 = [5] * 1000\n",
    "%timeit find_duplicates(trial_values2)\n",
    "%timeit better_find_duplicates(trial_values2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that `%timeit` (rather intelligently) opts for fewer loops since each loop is more intensive.  In this case, my loop behavior improves to  $103/204 \\approx 0.505$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can be shown that performance in this algorithm also increases when the list is sorted first (we assume that the sorting only need happen once).\n",
    "\n",
    "-   Compose a function `sorted_find_duplicates` which performs as above, except that `values` is sorted before the search is made.  (You may use `values.sort()`, which modifies the list in-place.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "nbgrader": {
     "grade": false,
     "grade_id": "sorted_find_duplicates",
     "locked": false,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# Write your function here.  This includes any necessary import statements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "nbgrader": {
     "grade": true,
     "grade_id": "sorted_find_duplicates-test",
     "locked": true,
     "points": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# it should pass this test---do NOT edit this cell\n",
    "from nose.tools import assert_equal\n",
    "\n",
    "test_values = ['a', 'a', 'b', 'd', 'a', 'b', 'c', 'd', 'a']\n",
    "test_result = sorted_find_duplicates(test_values)\n",
    "assert_equal(type(test_result), list, msg=\"\\nYour function doesn't return a list.\")\n",
    "assert_equal(len(test_result), 3, msg=\"\\nYour function does not return the correct number of duplicate items.\")\n",
    "assert_equal(test_result, ['a', 'b', 'd'], msg=\"\\nYour function returns the wrong items as duplicates.\")\n",
    "\n",
    "print('All tests passed successfully.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll try all three functions thus far—`find_duplicates`, `better_find_duplicates`, and `sorted_find_duplicates`—on a large random list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy.random as npr\n",
    "trial_values3 = npr.randint(0,10,size=1000)\n",
    "print(trial_values3)\n",
    "%timeit find_duplicates(trial_values3)\n",
    "%timeit better_find_duplicates(trial_values3)\n",
    "%timeit sorted_find_duplicates(trial_values3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice the pause after the first two runs of `%timeit`—this is the list being sorted during the first trial run of `sorted_find_duplicates`.  My performance is marginally better, on the order of $2\\%$ in this case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A very great improvement can often be achieved by moving from Python to C—in this case, NumPy, which has much of its actual numerical code written in the very efficient C language.\n",
    "\n",
    "C is a *compiled* language, meaning that the code is converted directly into machine language before being run.  This gives it a great deal of power and efficiency, which is why many numerical applications are written in C."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# although demonstrative, this is not a particularly efficient code\n",
    "import numpy as np\n",
    "\n",
    "def numpy_find_duplicates(values):\n",
    "    duplicates = []\n",
    "    values = np.array(values)\n",
    "    values.sort()\n",
    "    for i in range(0, len(values)):  # note that we are making the range explicit here\n",
    "        for j in range(i+1, len(values)):\n",
    "            if i == j:  # don't compare numbers[0] to numbers[0], etc.\n",
    "                continue\n",
    "            if values[i] == values[j] and values[j] not in duplicates:\n",
    "                duplicates.append(values[j])\n",
    "    \n",
    "    return duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy.random as npr\n",
    "trial_values3 = npr.randint(0,10,size=1000)\n",
    "print(trial_values3)\n",
    "%timeit find_duplicates(trial_values3)\n",
    "%timeit better_find_duplicates(trial_values3)\n",
    "%timeit sorted_find_duplicates(trial_values3)\n",
    "%timeit numpy_find_duplicates(trial_values3)  # note that sorting has already taken place as well"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm going to throw one more into the mix:  this one uses the SciPy `itemfreq` function, which tells you how many times each item occurs in a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.stats import itemfreq\n",
    "\n",
    "def scipy_find_duplicates(values):\n",
    "    duplicates = []\n",
    "    freqs = itemfreq(values)\n",
    "    \n",
    "    for i in freqs:\n",
    "        if i[1] > 1:\n",
    "            duplicates.append(i[0])\n",
    "    \n",
    "    return duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy.random as npr\n",
    "trial_values3 = npr.randint(0,10,size=1000)\n",
    "print(trial_values3)\n",
    "%timeit find_duplicates(trial_values3)\n",
    "%timeit better_find_duplicates(trial_values3)\n",
    "%timeit sorted_find_duplicates(trial_values3)\n",
    "%timeit numpy_find_duplicates(trial_values3)  # note that sorting has already taken place as well\n",
    "%timeit scipy_find_duplicates(trial_values3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, my values are:\n",
    "\n",
    "| function | best time | ratio to worst |\n",
    "|----------|-----------|----------------|\n",
    "| `find_duplicates` | 287 ms | 100% |\n",
    "| `better_find_duplicates` | 146 ms | 50.9% |\n",
    "| `sorted_find_duplicates` | 144 ms | 50.2% |\n",
    "| `numpy_find_duplicates` | 142 ms | 49.4% |\n",
    "| `scipy_find_duplicates` | 75.6 µs | 0.05% |\n",
    "\n",
    "In the last case, with `scipy`, there is some *serious* speedup taking place.  (NumPy could be similar if we used a more matrix-based algorithm, but the code gets messy so I'll spare you.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algorithm Scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Commonly you need to know how one or more algorithms performs with respect to data set size $n$.  In this section, you're going to calculate run times for various scenarios and plot the resulting performance curves (called scaling).\n",
    "\n",
    "In order to store these data for plotting, we are going to use a single array or data table, paired with algorithm names (the functions) and values of $n$ (the data set sizes).\n",
    "\n",
    "|                          | $n = 10$ | $n = 100$ | $n = 1\\,000$ | $n = 10\\,000$ | $n = 100\\,000$ |\n",
    "|--------------------------|---------|----------|-----------|------------|--------------|\n",
    "| `find_duplicates`        |         |          |           |            |              |\n",
    "| `better_find_duplicates` |         |          |           |            |              |\n",
    "| `sorted_find_duplicates` |         |          |           |            |              |\n",
    "| `numpy_find_duplicates`  |         |          |           |            |              |\n",
    "| `scipy_find_duplicates`  |         |          |           |            |              |               |\n",
    "\n",
    "Our goal is to fill in the values of this table and then plot it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "names = ['find_duplicates', 'better_find_duplicates', 'sorted_find_duplicates', 'numpy_find_duplicates', 'scipy_find_duplicates']\n",
    "n = [10, 100, 1000, 10000, 100000]\n",
    "table = np.zeros( (5, 5) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Python code analogue of `%timeit` is `timeit.timeit`.  Unfortunately, it doesn't know about the functions and variables in your greater Python environment or Jupyter notebook, so you have to redefine variables.  You also need to tell it how many times to test the code (keep this very low until you understand the data set's behavior!—around 1–10).  It is used as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import timeit\n",
    "timeit.timeit(stmt='sin(x)', setup='from numpy import sin; x=[5,6,7]', number=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll populate the cases one at a time for each value of $n$ in `n`.  (This means that most of your table will be zero as we start, but will fill in naturally as the following code executes.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "timeit-find_duplicates",
     "locked": false,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "defn_find_duplicates='''you should copy and paste your definition of find_duplicates from above here in this string'''\n",
    "defn_find_duplicates+='''\n",
    "import numpy.random as npr\n",
    "trial_values2 = npr.randint(0,10,size=1000)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "nbgrader": {
     "grade": false,
     "grade_id": "timeit-find_duplicates-test",
     "locked": false,
     "points": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "n_trials = 10\n",
    "t_trials = timeit.timeit(stmt='find_duplicates(trial_values2)', setup=defn_find_duplicates, number=n_trials)\n",
    "print('%.6f s'%(t_trials))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's more efficient (for you, the user) to put this in a loop as well:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "timeit-find_duplicates",
     "locked": false,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "defn_find_duplicates='''you should copy and paste your definition of find_duplicates from above here in this string'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "nbgrader": {
     "grade": true,
     "grade_id": "timeit-find_duplicates-test",
     "locked": true,
     "points": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "n_trials = 10\n",
    "for i,num in enumerate(n):\n",
    "    defn_find_duplicates+='''\n",
    "import numpy.random as npr\n",
    "trial_values2 = npr.randint(0,%d,size=1000)\n",
    "    '''%num\n",
    "    t_trials = timeit.timeit(stmt='find_duplicates(trial_values2)', setup=defn_find_duplicates, number=n_trials)\n",
    "    table[0,i] = (t_trials)\n",
    "\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "timeit-better_find_duplicates",
     "locked": false,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "defn_better_find_duplicates='''you should copy and paste your definition of better_find_duplicates from above here in this string'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "nbgrader": {
     "grade": true,
     "grade_id": "timeit-better_find_duplicates-test",
     "locked": true,
     "points": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "n_trials = 10\n",
    "for i,num in enumerate(n):\n",
    "    defn_better_find_duplicates+='''\n",
    "import numpy.random as npr\n",
    "trial_values2 = npr.randint(0,%d,size=1000)\n",
    "    '''%num\n",
    "    t_trials = timeit.timeit(stmt='better_find_duplicates(trial_values2)', setup=defn_better_find_duplicates, number=n_trials)\n",
    "    table[1,i] = (t_trials)\n",
    "\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "nbgrader": {
     "grade": false,
     "grade_id": "timeit-sorted_find_duplicates",
     "locked": false,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "defn_sorted_find_duplicates='''you should copy and paste your definition of sorted_find_duplicates from above here in this string'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "timeit-sorted_find_duplicates-test",
     "locked": true,
     "points": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "n_trials = 10\n",
    "for i,num in enumerate(n):\n",
    "    defn_sorted_find_duplicates+='''\n",
    "import numpy.random as npr\n",
    "trial_values2 = npr.randint(0,%d,size=1000)\n",
    "    '''%num\n",
    "    t_trials = timeit.timeit(stmt='sorted_find_duplicates(trial_values2)', setup=defn_sorted_find_duplicates, number=n_trials)\n",
    "    table[2,i] = (t_trials)\n",
    "\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "timeit-numpy_find_duplicates",
     "locked": false,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "defn_numpy_find_duplicates='''you should copy and paste your definition of numpy_find_duplicates from above here in this string'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "nbgrader": {
     "grade": true,
     "grade_id": "timeit-numpy_find_duplicates-test",
     "locked": true,
     "points": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "n_trials = 10\n",
    "for i,num in enumerate(n):\n",
    "    defn_numpy_find_duplicates+='''\n",
    "import numpy.random as npr\n",
    "trial_values2 = npr.randint(0,%d,size=1000)\n",
    "    '''%num\n",
    "    t_trials = timeit.timeit(stmt='numpy_find_duplicates(trial_values2)', setup=defn_numpy_find_duplicates, number=n_trials)\n",
    "    table[3,i] = (t_trials)\n",
    "\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "timeit-scipy_find_duplicates",
     "locked": false,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "defn_scipy_find_duplicates='''you should copy and paste your definition of scipy_find_duplicates from above here in this string'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "nbgrader": {
     "grade": true,
     "grade_id": "timeit-scipy_find_duplicates-test",
     "locked": true,
     "points": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "n_trials = 10\n",
    "for i,num in enumerate(n):\n",
    "    defn_scipy_find_duplicates+='''\n",
    "import numpy.random as npr\n",
    "trial_values2 = npr.randint(0,%d,size=1000)\n",
    "    '''%num\n",
    "    t_trials = timeit.timeit(stmt='scipy_find_duplicates(trial_values2)', setup=defn_scipy_find_duplicates, number=n_trials)\n",
    "    table[4,i] = (t_trials)\n",
    "\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the table is populated, let's plot the data a couple of different ways.  We'll do this a *bit* differently, and instead of just plotting directly we'll write a function which returns the plot.  Then we can plot it directly.\n",
    "\n",
    "As an example, this block of code defines a function `plot_sin` which plots a sine function and returns it.  Note that our plotting code is becoming more complicated (since we are going to do more sophisticated things with it).  Now we have a `fig` variable (the figure, that is, the \"whole thing\") and an `axes` variable (the plot and data together).  It's the latter that we plot on, and that needs to be returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "def plot_sin():\n",
    "    # Get the data.\n",
    "    x  = np.linspace(0,2*np.pi,100)\n",
    "    y1 = np.sin(x)\n",
    "    y2 = np.cos(x)\n",
    "    \n",
    "    # Plot the data.\n",
    "    fig, axes = plt.subplots(nrows=1, ncols=1)\n",
    "    axes.plot(x, y1, label='sine')\n",
    "    axes.plot(x, y2, label='cosine')\n",
    "    \n",
    "    # Arrange plot features for the end viewer.\n",
    "    axes.set_xlabel('n')\n",
    "    axes.set_ylabel('t')\n",
    "    axes.legend(loc='best')  # this makes the legend appear where it covers the fewest data points\n",
    "    \n",
    "    return axes\n",
    "\n",
    "my_axes = plot_sin()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   Compose a function `plot_lines` which accepts a table `my_table`, a list of functions used to generate the table `my_funcs`, and a list of data set sizes used to generate the table `my_n`.  This function should plot each row of the table data against the data set sizes, with each line's label coming from the proper row in `my_funcs` (as above).  A representative line may look like:\n",
    "        \n",
    "        axes.plot(my_n, my_table[2], label=my_funcs[2])\n",
    "    \n",
    "    Label the x- and y-axes with `'n'` and `'t'` (as above).  The function should return the resulting `axes` (as above)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "nbgrader": {
     "grade": false,
     "grade_id": "plot_lines",
     "locked": false,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# Write your function here.  This includes any necessary import statements.\n",
    "def plot_lines(my_table, my_funcs, my_n):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "plot_lines-test",
     "locked": true,
     "points": 5,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# it should pass this test---do NOT edit this cell\n",
    "# these are worth five points\n",
    "import matplotlib as mpl\n",
    "from nose.tools import assert_equal, assert_is_not\n",
    "\n",
    "test_axes = plot_lines(table, names, n)\n",
    "assert_equal(isinstance(test_axes, mpl.axes.Axes), True, msg=\"\\nYour function does not return axes.\")\n",
    "assert_equal(len(test_axes.lines), 5, msg=\"\\nYour plot does not have the correct number of lines.\")\n",
    "assert_is_not(len(test_axes.xaxis.get_label_text()), 0, msg=\"\\nYour plot does not have labels on the x-axis.\")\n",
    "assert_is_not(len(test_axes.yaxis.get_label_text()), 0, msg=\"\\nYour plot does not have labels on the y-axis.\")\n",
    "assert_equal(test_axes.legend_.get_visible(), True, msg=\"\\nYour plot does not have a legend.\")\n",
    "\n",
    "print('All tests passed successfully.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The underlying behavior can also be illuminated by changing the plot type from a linear scale (1, 2, 3, etc.) to a *logarithmic* scale (1, 10, 100, etc.).  In MatPlotLib, this can be accomplished by changing from using `plot` to using `loglog` (arguments stay the same).\n",
    "\n",
    "-   Compose a function `plot_logs` which does the same as `plot_lines` above, but uses `loglog` instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "nbgrader": {
     "grade": false,
     "grade_id": "plot_logs",
     "locked": false,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# Write your function here.  This includes any necessary import statements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "plot_logs-test",
     "locked": true,
     "points": 5,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# it should pass this test---do NOT edit this cell\n",
    "# these are worth five points\n",
    "import matplotlib as mpl\n",
    "from nose.tools import assert_equal, assert_is_not\n",
    "\n",
    "test_axes = plot_logs(table, names, n)\n",
    "assert_equal(isinstance(test_axes, mpl.axes.Axes), True, msg=\"\\nYour function does not return axes.\")\n",
    "assert_equal(len(test_axes.lines), 5, msg=\"\\nYour plot does not have the correct number of lines.\")\n",
    "assert_is_not(len(test_axes.xaxis.get_label_text()), 0, msg=\"\\nYour plot does not have labels on the x-axis.\")\n",
    "assert_is_not(len(test_axes.yaxis.get_label_text()), 0, msg=\"\\nYour plot does not have labels on the y-axis.\")\n",
    "assert_equal(test_axes.legend_.get_visible(), True, msg=\"\\nYour plot does not have a legend.\")\n",
    "#assert_equal(test_result, ['a', 'b', 'd'], msg=\"\\nYour plot is not logarithmic on the x-axis.\")\n",
    "#ax.set_yscale(\"log\") \n",
    "\n",
    "print('All tests passed successfully.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The log-log plot conveniently lets you predict how your algorithm will perform as you move to larger and larger problems by looking at the plot trend.\n",
    "\n",
    "Such is the art of scaling.  You are equipped now to compare the behavior of various methods in your work, and to predict how that behavior will change as you move to bigger challenges and data sets."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "IPython (Python 3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
